<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Title</title>
    <meta http-equiv="origin-trial"
          content="AuT39+Duz+ZRtx1SlkTa2EJAL3fE4ffZq72D+4KnjZkx0XC9g6GL+kteswN1p9S6Kd4NJUlAwMWB1VWwr3lCqAgAAABleyJvcmlnaW4iOiJodHRwczovL3JlZGNhbWVsLmdpdGh1Yi5pbzo0NDMiLCJmZWF0dXJlIjoiV2ViR1BVIiwiZXhwaXJ5IjoxNjc1MjA5NTk5LCJpc1N1YmRvbWFpbiI6dHJ1ZX0=">
    <meta http-equiv="origin-trial"
          content="AoObp2NQ8sEb9+TWvbU/cWFBaNRNGXZtCp6yZSrjuqlH+JDRV9cP+abD9k2ydtE92JpehZbovmhZ2pKiG8obLAYAAABJeyJvcmlnaW4iOiJodHRwOi8vbG9jYWxob3N0OjMwMDMiLCJmZWF0dXJlIjoiV2ViR1BVIiwiZXhwaXJ5IjoxNjc1MjA5NTk5fQ==">

    <style>
        html, body {
            padding: 0;
            margin: 0;
            width: 100%;
            height: 100%;
        }
    </style>
</head>
<body>
<canvas width="100%" height="100%" id="cvs"/>
<script>

	const run = async () => {
		const canvasW = 512
		const canvasH = 512

		const gpu = navigator.gpu
		console.log(gpu)
		const adapter = await gpu.requestAdapter(

		)
		console.log(adapter)
		const device = await adapter.requestDevice(

		)
		console.log(device)
		document.getElementById('cvs').width = canvasW
		document.getElementById('cvs').height = canvasH
		const context = document.getElementById('cvs').getContext('webgpu')
		console.log(context)

		/**
		 *
		 * @type {GPUCanvasConfiguration}
		 */
		const canvasConfiguration = {
			device,
			format: navigator.gpu.getPreferredCanvasFormat(),
			alphaMode: "premultiplied",
			usage: GPUTextureUsage.COPY_DST | GPUTextureUsage.COPY_SRC | GPUTextureUsage.RENDER_ATTACHMENT

		}
		context.configure(canvasConfiguration)

		const vertexCode = `
struct OutData {
  @builtin(position) position : vec4<f32>,
  @location(0) uv: vec2<f32>,
};
@vertex
fn main( @builtin(vertex_index) VertexIndex : u32 ) -> OutData {
var pos = array<vec4<f32>, 6>(
    vec4<f32>(-1, -1, 0.0, 1.0),
    vec4<f32>(1, -1, 1.0, 1.0),
    vec4<f32>(-1,  1,  0.0, 0.0),
    //
   vec4<f32>(-1, 1,    0.0, 0.0),
   vec4<f32>(1, -1,   1.0, 1.0),
   vec4<f32>(1, 1,   1.0, 0.0),

  );
   var outData : OutData;
  outData.position = vec4<f32>(pos[VertexIndex].xy, 0.0, 1.0);
  outData.uv = pos[VertexIndex].zw;
  return outData;
}
		`
		const fragmentCode = `

@group(0) @binding(0) var _Sampler: sampler;
@group(0) @binding(1) var _Texture: texture_2d<f32>;
@fragment
fn main(@location(0) uv: vec2<f32>) -> @location(0) vec4<f32> {
  return textureSample(_Texture,_Sampler, uv);
}
		`
		/**
		 *
		 * @type {GPUShaderModuleDescriptor}
		 */
		const vModuleDescriptor = {
			code: vertexCode
		}
		/**
		 *
		 * @type {GPUShaderModuleDescriptor}
		 */
		const fModuleDescriptor = {
			code: fragmentCode
		}
		/**
		 *
		 * @type {GPUShaderModule}
		 */
		const vModule = device.createShaderModule(vModuleDescriptor)
		/**
		 *
		 * @type {GPUShaderModule}
		 */
		const fModule = device.createShaderModule(fModuleDescriptor)
		console.log(vModule)
		console.log(fModule)

		/**
		 *
		 * @type {GPUBindGroupLayoutDescriptor}
		 */
		const bindGroupLayoutDescriptor = {
			entries: [
				{
					binding: 0,
					visibility: GPUShaderStage.FRAGMENT,
					sampler: {
						type: 'filtering',
					},
				},
				{
					binding: 1,
					visibility: GPUShaderStage.FRAGMENT,
					texture: {},
				}
			]
		}
		const bindGroupLayout = device.createBindGroupLayout(bindGroupLayoutDescriptor)
		console.log(bindGroupLayout)

		function makeWebGPUTexture(gpuDevice, source, generateMipmaps = true, label) {
			// 텍스쳐에 대한 정의를 내리고
			const textureDescriptor = {
				size: {width: source.width, height: source.height},
				format: 'rgba8unorm',
				usage: GPUTextureUsage.RENDER_ATTACHMENT | GPUTextureUsage.TEXTURE_BINDING | GPUTextureUsage.COPY_DST | GPUTextureUsage.COPY_SRC,
				label
			};
			// 밉맵을 생성할꺼면 소스를 계산해서... 밉맵 카운트를 추가 정의한다.
			if (generateMipmaps) {
				// Compute how many mip levels are needed for a full chain.
				textureDescriptor.mipLevelCount = Math.floor(Math.log2(Math.max(source.width, source.height))) + 1;
				// Needed in order to use render passes to generate the mipmaps.
				textureDescriptor.usage |= GPUTextureUsage.RENDER_ATTACHMENT;
			}
			// 생성할 원본 소스를 생성한다.
			const texture = gpuDevice.createTexture(textureDescriptor);
			// 생성한 텍스쳐에 데이터를 밀어넣는다.
			gpuDevice.queue.copyExternalImageToTexture({source}, {texture}, textureDescriptor.size);

			return texture;
		}

		let testTexture
		const url = './crate.png'
		// const url = './test.png'
		await fetch(url).then(response => response.blob().then(blob => createImageBitmap(blob))).then(imgBitmap => {
			console.log(imgBitmap)
			testTexture = makeWebGPUTexture(device, imgBitmap, true, url)
		})
		console.log(testTexture)

		/**
		 *
		 * @type {GPUBindGroupDescriptor}
		 */
		const bindGroupDescriptor = {
			layout: bindGroupLayout,
			entries: [
				{
					binding: 0,
					resource: device.createSampler({minFilter: 'linear'})
				},
				{
					binding: 1,
					resource: testTexture.createView(
						{
							baseMipLevel: 0,
							mipLevelCount: 1
						}
					)
				}
			]
		}
		/**
		 *
		 * @type {GPUBindGroup}
		 */
		const bindGroup = device.createBindGroup(bindGroupDescriptor)
		console.log(bindGroup)

		/**
		 *
		 * @type {GPUPipelineLayoutDescriptor}
		 */
		const pipelineLayoutDescriptor = {
			bindGroupLayouts: [bindGroupLayout]
		}
		const pipelineLayout = device.createPipelineLayout(pipelineLayoutDescriptor)

		/**
		 *
		 * @type {GPURenderPipelineDescriptor}
		 */
		const pipelineDescriptor = {
			layout: pipelineLayout,
			vertex: {
				module: vModule,
				entryPoint: 'main'
			},
			fragment: {
				module: fModule,
				entryPoint: 'main',
				targets: [
					{
						format: navigator.gpu.getPreferredCanvasFormat()
					}
				]
			}
		}
		/**
		 *
		 * @type {GPURenderPipeline}
		 */
		const pipeline = device.createRenderPipeline(pipelineDescriptor)
		console.log(pipeline)

		const renderTexture = device.createTexture({
			size: {
				width: canvasW,
				height: canvasH,
			},
			format: gpu.getPreferredCanvasFormat(),
			usage: GPUTextureUsage.TEXTURE_BINDING | GPUTextureUsage.COPY_DST | GPUTextureUsage.RENDER_ATTACHMENT
		})
		console.log('renderTexture', renderTexture)
		/**
		 *
		 * @type {GPUTextureView}
		 */
		const renderTextureView = renderTexture.createView(
			{
				baseMipLevel: 0,
				mipLevelCount: 1
			}
		)

		/**
		 *
		 * @type {GPURenderPassColorAttachment}
		 */
		const colorAttachment = {
			view: renderTextureView,
			loadOp: "clear",
			storeOp: 'store'
		}

		/**
		 *
		 * @type {GPUCommandEncoder}
		 */
		const commandEncoder = device.createCommandEncoder()

		/**
		 *
		 * @type {GPURenderPassDescriptor}
		 */
		const renderPassDescriptor = {
			colorAttachments: [
				colorAttachment
			]
		}
		/**
		 *
		 * @type {GPURenderPassEncoder}
		 */

		const passEncoder = commandEncoder.beginRenderPass(renderPassDescriptor)
		passEncoder.setPipeline(pipeline)
		passEncoder.setBindGroup(0, bindGroup)
		passEncoder.draw(6, 1, 0, 0);
		passEncoder.end()
		device.queue.submit([commandEncoder.finish()])

		// 결과를 일단 복사하고...

		//TODO compute Shader 처리

		let effectOutputTexture = device.createTexture({
			size: {
				width: renderTexture.width,
				height: renderTexture.height,
			},
			format: 'rgba8unorm',
			usage: GPUTextureUsage.TEXTURE_BINDING | GPUTextureUsage.STORAGE_BINDING | GPUTextureUsage.COPY_SRC
		})
		// 쓰레드 지정인가?
		const FILTER_SIZE = 8
		const WORK_SIZE_X = 16
		const WORK_SIZE_Y = 16
		const WORK_SIZE_Z = 1
		const DISPATCH_X = Math.ceil(canvasW / WORK_SIZE_X)
		const DISPATCH_Y = Math.ceil(canvasH / WORK_SIZE_Y)
		const DISPATCH_Z = 1
		const computeCode = `
            @group(0) @binding(0) var _Texture : texture_2d<f32>;
            @group(0) @binding(1) var outputTex : texture_storage_2d<rgba8unorm, write>;
            const workSizeX = ${WORK_SIZE_X};
            const workSizeY = ${WORK_SIZE_Y};
            const workSizeZ = ${WORK_SIZE_Z};
            const u_filterSize:u32 = ${FILTER_SIZE};
            var<workgroup> tile : array<vec4<f32>, workSizeX * u_filterSize / workSizeX * workSizeY * workSizeZ>;
            @compute @workgroup_size(workSizeX,workSizeY,workSizeZ)

            fn main (
                @builtin(workgroup_id) WorkGroupID : vec3<u32>,
                @builtin(global_invocation_id) global_id : vec3<u32>,
                @builtin(local_invocation_id) LocalInvocationID : vec3<u32>,
                @builtin(local_invocation_index) LocalInvocationINDEX : u32

            ){
                let dims = (textureDimensions(_Texture,0));
                let globalUV:vec2<u32> = global_id.xy ;
                let deltaX:u32 =  (globalUV.x % u_filterSize);
                let deltaY:u32 =  (globalUV.y % u_filterSize);
                let coord:vec2<u32> = vec2<u32>( globalUV.x - deltaX , globalUV.y - deltaY );

                var saveYn = false;

                let ratioX = u_filterSize / workSizeX;
                let ratioY = u_filterSize / workSizeY;
                // 워크 사이즈 보다 클떄
                var tX = u32(coord.x / u_filterSize);
                var tY = u32(coord.y / u_filterSize);
                var newIndex = tX + tY * u_filterSize ;



                if(coord.x>=0 && coord.y>=0){
                     if(
                        (
                            globalUV.x % u_filterSize == 0
                            || globalUV.y % u_filterSize == 0
                        )
                        ||
                        (
                            globalUV.x % workSizeX == 0
                            || globalUV.y % workSizeY == 0
                        )
                    ){
                       saveYn = true;
                    }
                }



                if(saveYn) {
                   tile[newIndex] = textureLoad(_Texture, coord ,0);
                }else{

                }

                workgroupBarrier();
                // 워크 그룹과 디스패치 사이즈관계
                //textureStore(outputTex, globalUV, vec4<f32>(f32(WorkGroupID.x)/f32(${DISPATCH_X}),f32(WorkGroupID.y)/f32(${DISPATCH_Y}),0,1));
                // 로컬인포케이션과 워크 사이즈의 관계
                //textureStore(outputTex, globalUV, vec4<f32>(f32(LocalInvocationID.x)/f32(workSizeX),f32(LocalInvocationID.y)/f32(workSizeY),0,1));
                // 그려보면
                if(saveYn) {
                   let finalColor = tile[newIndex];
                   textureStore(outputTex, globalUV, finalColor);
                }else{
                   let finalColor = tile[newIndex];
                   textureStore(outputTex, globalUV, finalColor);
                }


            };

        `
		const cModule = device.createShaderModule({
			code: computeCode,
		})

		const bindGroupLayout_compute = device.createBindGroupLayout({
			entries: [
				{
					binding: 0,
					visibility: GPUShaderStage.COMPUTE,
					texture: {}
				},
				{
					binding: 1,
					visibility: GPUShaderStage.COMPUTE,
					storageTexture: {
						format: 'rgba8unorm'
					}
				},
			]
		})

		const bindGroup_compute = device.createBindGroup({
			layout: bindGroupLayout_compute,
			entries: [

				{
					binding: 0,
					resource: renderTexture.createView()

				},
				{
					binding: 1,
					resource: effectOutputTexture.createView()

				},
			]
		})

		const pipeline_compute = device.createComputePipeline({
			layout: device.createPipelineLayout({
				bindGroupLayouts: [
					bindGroupLayout_compute,
				]
			}),
			compute: {
				module: cModule,
				entryPoint: 'main',
			}
		})
		const startTime = performance.now()
		const commentEncode_compute = device.createCommandEncoder()
		const computePassEncoder = commentEncode_compute.beginComputePass()

		computePassEncoder.setPipeline(pipeline_compute)
		computePassEncoder.setBindGroup(0, bindGroup_compute)
		computePassEncoder.dispatchWorkgroups(DISPATCH_X, DISPATCH_Y, DISPATCH_Z);
		computePassEncoder.end();
		device.queue.submit([commentEncode_compute.finish()]);

		// return
		// console.log(pipeline_compute)
		console.log('time', performance.now() - startTime)
		{
			const vertexCode2 = `

struct OutData {
  @builtin(position) position : vec4<f32>,
  @location(0) uv: vec2<f32>,
};
@vertex
fn main( @builtin(vertex_index) VertexIndex : u32 ) -> OutData {
  var pos = array<vec4<f32>, 6>(
  vec4<f32>(-1, -1, 0.0, 1.0),
    vec4<f32>(1, -1, 1.0, 1.0),
    vec4<f32>(-1,  1,  0.0, 0.0),
    //
   vec4<f32>(-1, 1,    0.0, 0.0),
   vec4<f32>(1, -1,   1.0, 1.0),
   vec4<f32>(1, 1,   1.0, 0.0),

  );
   var outData : OutData;
  outData.position = vec4<f32>(pos[VertexIndex].xy, 0.0, 1.0);
  outData.uv = pos[VertexIndex].zw;
  return outData;
}`
			const vModuleDescriptor = {
				code: vertexCode2
			}
			const fragmentCode2 = `
@group(0) @binding(0) var _Sampler: sampler;
@group(0) @binding(1) var _Texture: texture_2d<f32>;
@fragment
fn main(@location(0) uv: vec2<f32>) -> @location(0) vec4<f32> {
  return textureSample(_Texture,_Sampler, uv);
}

		`
			const fModuleDescriptor = {
				code: fragmentCode2
			}
			/**
			 *
			 * @type {GPUShaderModule}
			 */
			const vModule = device.createShaderModule(vModuleDescriptor)
			/**
			 *
			 * @type {GPUShaderModule}
			 */
			const fModule = device.createShaderModule(fModuleDescriptor)
			console.log(vModule)
			console.log(fModule)

			/**
			 *
			 * @type {GPUBindGroupLayoutDescriptor}
			 */
			const bindGroupLayoutDescriptor = {
				entries: [
					{
						binding: 0,
						visibility: GPUShaderStage.FRAGMENT,
						sampler: {
							type: 'filtering',
						},
					},
					{
						binding: 1,
						visibility: GPUShaderStage.FRAGMENT,
						texture: {},
					}
				]
			}
			const bindGroupLayout = device.createBindGroupLayout(bindGroupLayoutDescriptor)
			console.log(bindGroupLayout)
			/**
			 *
			 * @type {GPUBindGroupDescriptor}
			 */
			const bindGroupDescriptor = {
				layout: bindGroupLayout,
				entries: [
					{
						binding: 0,
						resource: device.createSampler({minFilter: 'linear'})
					},
					{
						binding: 1,
						resource: effectOutputTexture.createView()
					}
				]
			}
			/**
			 *
			 * @type {GPUBindGroup}
			 */
			const bindGroup = device.createBindGroup(bindGroupDescriptor)
			console.log(bindGroup)

			/**
			 *
			 * @type {GPUPipelineLayoutDescriptor}
			 */
			const pipelineLayoutDescriptor = {
				bindGroupLayouts: [bindGroupLayout]
			}
			const pipelineLayout = device.createPipelineLayout(pipelineLayoutDescriptor)

			/**
			 *
			 * @type {GPURenderPipelineDescriptor}
			 */
			const pipelineDescriptor = {
				layout: pipelineLayout,
				vertex: {
					module: vModule,
					entryPoint: 'main'
				},
				fragment: {
					module: fModule,
					entryPoint: 'main',
					targets: [
						{
							format: navigator.gpu.getPreferredCanvasFormat()
						}
					]
				}
			}
			/**
			 *
			 * @type {GPURenderPipeline}
			 */
			const pipeline = device.createRenderPipeline(pipelineDescriptor)
			console.log(pipeline)

			const renderTexture = context.getCurrentTexture()
			/**
			 *
			 * @type {GPUTextureView}
			 */
			const renderTextureView2 = renderTexture.createView()

			/**
			 *
			 * @type {GPURenderPassColorAttachment}
			 */
			const colorAttachment = {
				view: renderTextureView2,
				loadOp: "clear",
				storeOp: 'store'
			}

			/**
			 *
			 * @type {GPUCommandEncoder}
			 */
			const commandEncoder = device.createCommandEncoder()

			/**
			 *
			 * @type {GPURenderPassDescriptor}
			 */
			const renderPassDescriptor = {
				colorAttachments: [
					colorAttachment
				]
			}
			/**
			 *
			 * @type {GPURenderPassEncoder}
			 */
			const passEncoder = commandEncoder.beginRenderPass(renderPassDescriptor)
			passEncoder.setPipeline(pipeline)
			passEncoder.setBindGroup(0, bindGroup)
			passEncoder.draw(6, 1, 0, 0);
			passEncoder.end()
			device.queue.submit([commandEncoder.finish()])
		}

	}
	run()

</script>
</body>
</html>
